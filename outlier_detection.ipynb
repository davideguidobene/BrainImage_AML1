{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f12b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2, SelectPercentile, mutual_info_regression\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db91bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 4426008 #np.random.randint(2**32)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00070104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_X(x_tr = None, x_ts = None):\n",
    "  if x_tr is None:\n",
    "    x_tr = x_train\n",
    "  if x_ts is None:\n",
    "    x_ts = x_test\n",
    "  return pd.concat([x_tr, x_ts], join = \"inner\")\n",
    "\n",
    "def full_nans(nans_tr = None, nans_ts = None):\n",
    "  if nans_tr is None:\n",
    "    nans_tr = nans_train\n",
    "  if nans_ts is None:\n",
    "    nans_ts = nans_test\n",
    "  return pd.concat([nans_tr, nans_ts], join = \"inner\")\n",
    "\n",
    "def X_with_na(x = None, nans = None):\n",
    "    if x is None:\n",
    "        x = full_X()\n",
    "    if nans is None:\n",
    "        nans = full_nans()\n",
    "    return pd.concat([x, nans], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d0aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "just_scoring = False\n",
    "if just_scoring:\n",
    "  folder = \"just_scoring/\"\n",
    "else:\n",
    "  folder = \"testing/\"\n",
    "folder = folder + \"\"\n",
    "raw = folder + \"nan_filled/\"\n",
    "preprocessed = folder + \"outlier_detected/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a813a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(raw + 'X_train_preprocessed.csv',index_col=['id'])\n",
    "x_test = pd.read_csv(raw + 'X_test_preprocessed.csv',index_col=['id'])\n",
    "y_train = pd.read_csv(raw + 'y_train_preprocessed.csv',index_col=['id'])\n",
    "y_test = pd.read_csv(raw + 'y_test_preprocessed.csv',index_col=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc48b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "nans_train = pd.read_csv(raw + 'nans_train_preprocessed.csv',index_col=['id'])\n",
    "nans_test = pd.read_csv(raw + 'nans_test_preprocessed.csv',index_col=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c141526",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = RobustScaler()\n",
    "s.fit(full_X())\n",
    "x_train[[col for col in x_train.columns]] = s.transform(x_train)\n",
    "x_test[[col for col in x_train.columns]] = s.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e713989a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 828)\n",
      "(1212, 828)\n",
      "1\n",
      "(1208, 828)\n",
      "(1211, 828)\n",
      "CPU times: total: 3min 49s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train_old = x_train.copy()\n",
    "\n",
    "for i in range(2):\n",
    "    print(i)\n",
    "    if i>=0.5:\n",
    "        model=IsolationForest(n_estimators=5000, random_state=np.random.randint(0, 2**31), n_jobs=-1)\n",
    "        model.fit(np.array(full_X()))\n",
    "        is_anomaly = model.predict(np.array(x_train))\n",
    "    else:\n",
    "        nei_size = np.floor(np.sqrt(full_X().shape[0])).astype(int)\n",
    "        model=LocalOutlierFactor(n_neighbors = nei_size, leaf_size = nei_size*1.5)\n",
    "        is_anomaly = model.fit_predict(full_X())[:x_train.shape[0]]\n",
    "    x_train['anomaly'] = is_anomaly\n",
    "    y_train['anomaly'] = is_anomaly\n",
    "    x_train = x_train[x_train.anomaly > 0]\n",
    "    y_train = y_train[y_train.anomaly > 0]\n",
    "    x_train = x_train.drop('anomaly',axis=1)\n",
    "    y_train = y_train.drop('anomaly',axis=1)\n",
    "\n",
    "    while x_train_old.shape[0]!=x_train.shape[0]:\n",
    "        print(x_train.shape)\n",
    "        print(x_train_old.shape)\n",
    "        x_train_old = x_train.copy()\n",
    "        if i>=0.5:\n",
    "            model=IsolationForest(n_estimators=5000, random_state=np.random.randint(0, 2**31), n_jobs=-1)\n",
    "            model.fit(np.array(full_X()))\n",
    "            is_anomaly = model.predict(np.array(x_train))\n",
    "        else:\n",
    "            nei_size = np.floor(np.sqrt(full_X().shape[0])).astype(int)\n",
    "            model=LocalOutlierFactor(n_neighbors = nei_size, leaf_size = nei_size*1.5)\n",
    "            is_anomaly = model.fit_predict(full_X())[:x_train.shape[0]]\n",
    "        x_train['anomaly'] = is_anomaly\n",
    "        y_train['anomaly'] = is_anomaly\n",
    "        x_train = x_train[x_train.anomaly > 0]\n",
    "        y_train = y_train[y_train.anomaly > 0]\n",
    "        x_train = x_train.drop('anomaly',axis=1)\n",
    "        y_train = y_train.drop('anomaly',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff1498a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1111, 828)\n"
     ]
    }
   ],
   "source": [
    "is_anomaly = np.ones(x_train.shape[0]).astype(bool)\n",
    "for i in range(2):   \n",
    "    if i>=0.5:\n",
    "        model=IsolationForest(n_estimators=5000, contamination = float(0.05), random_state=np.random.randint(0, 2**31), n_jobs=-1)\n",
    "        model.fit(np.array(full_X()))\n",
    "        new_anomaly = model.predict(np.array(x_train)) > 0\n",
    "    else:\n",
    "        nei_size = np.floor(np.sqrt(full_X().shape[0])).astype(int)\n",
    "        model=LocalOutlierFactor(n_neighbors = nei_size, contamination = float(0.05), leaf_size = nei_size*1.5)\n",
    "        new_anomaly = model.fit_predict(full_X())[:x_train.shape[0]] > 0\n",
    "    is_anomaly = is_anomaly & new_anomaly\n",
    "x_train['anomaly'] = is_anomaly\n",
    "y_train['anomaly'] = is_anomaly\n",
    "x_train = x_train[x_train.anomaly]\n",
    "y_train = y_train[y_train.anomaly]\n",
    "x_train = x_train.drop('anomaly',axis=1)\n",
    "y_train = y_train.drop('anomaly',axis=1)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45f7948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1087, 828)\n"
     ]
    }
   ],
   "source": [
    "is_anomaly = np.zeros(x_train.shape[0]).astype(bool)\n",
    "for i in range(2):   \n",
    "    if i>=0.5:\n",
    "        model=IsolationForest(n_estimators=5000, contamination = float(0.1), random_state=np.random.randint(0, 2**31), n_jobs=-1)\n",
    "        model.fit(np.array(full_X()))\n",
    "        new_anomaly = model.predict(np.array(x_train)) > 0\n",
    "    else:\n",
    "        nei_size = np.floor(np.sqrt(full_X().shape[0])).astype(int)\n",
    "        model=LocalOutlierFactor(n_neighbors = nei_size, contamination = float(0.1), leaf_size = nei_size*1.5)\n",
    "        new_anomaly = model.fit_predict(full_X())[:x_train.shape[0]] > 0\n",
    "    is_anomaly = is_anomaly | new_anomaly\n",
    "x_train['anomaly'] = is_anomaly\n",
    "y_train['anomaly'] = is_anomaly\n",
    "x_train = x_train[x_train.anomaly]\n",
    "y_train = y_train[y_train.anomaly]\n",
    "x_train = x_train.drop('anomaly',axis=1)\n",
    "y_train = y_train.drop('anomaly',axis=1)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2a6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv(preprocessed + 'X_train_preprocessed.csv',index_label=\"id\")\n",
    "x_test.to_csv(preprocessed + 'X_test_preprocessed.csv',index_label=\"id\")\n",
    "y_train.to_csv(preprocessed + 'y_train_preprocessed.csv',index_label=\"id\")\n",
    "y_test.to_csv(preprocessed + 'y_test_preprocessed.csv',index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d104fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#auto, Nonan\n",
    "is_anomaly = np.zeros(x_train.shape[0])\n",
    "n_attempts = 50\n",
    "for _ in range(n_attempts):\n",
    "    model=IsolationForest(n_estimators=150, random_state=np.random.randint(0, 2**31), n_jobs=-1)\n",
    "    model.fit(np.array(full_X()))\n",
    "    is_anomaly += model.predict(np.array(x_train))/n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc1ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#contamination, Nonan\n",
    "is_anomaly4 = np.zeros(x_train.shape[0])\n",
    "n_attempts = 50\n",
    "for _ in range(n_attempts):\n",
    "    model=IsolationForest(n_estimators=150, max_samples='auto', contamination=float(0.2), random_state=np.random.randint(0, 2**31), n_jobs=-1)\n",
    "    model.fit(np.array(full_X()))\n",
    "    is_anomaly4 += model.predict(np.array(x_train))/n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26fa971",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#auto, nan\n",
    "is_anomaly3 = np.zeros(x_train.shape[0])\n",
    "n_attempts = 50\n",
    "for _ in range(n_attempts):\n",
    "    model=IsolationForest(n_estimators=150, random_state=np.random.randint(0, 2**31), n_jobs=-1)\n",
    "    model.fit(np.array(X_with_na()))\n",
    "    is_anomaly3 += model.predict(np.array(X_with_na(x_train, nans_train)))/n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423736bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#contamination, nan\n",
    "is_anomaly2 = np.zeros(x_train.shape[0])\n",
    "n_attempts = 50\n",
    "for _ in range(n_attempts):\n",
    "    model=IsolationForest(n_estimators=150, max_samples='auto', contamination=float(0.2), random_state=np.random.randint(0, 2**31), n_jobs=-1)\n",
    "    model.fit(np.array(X_with_na()))\n",
    "    is_anomaly2 += model.predict(np.array(X_with_na(x_train, nans_train)))/n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e035cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "is_anomaly5 = np.zeros(x_train.shape[0])\n",
    "n_attempts = 1\n",
    "for _ in range(n_attempts):\n",
    "    model=IsolationForest(n_estimators=150, max_samples='auto', contamination=float(0.2), random_state=np.random.randint(0, 2**31), n_jobs=-1)\n",
    "    model.fit(np.array(x_train))\n",
    "    is_anomaly5 += model.predict(np.array(x_train))/n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(is_anomaly)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.index[is_anomaly5<=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd6785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(is_anomaly5)[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.index[is_anomaly5<=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(is_anomaly2)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.index[is_anomaly2<=-0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f9c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_anomaly2[is_anomaly<=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ce30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(is_anomaly3)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.index[is_anomaly3<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(is_anomaly4)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bc85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.index[is_anomaly4<=-0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c1e13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
