{"cells":[{"cell_type":"markdown","metadata":{"id":"0xhRMlM8Qqj2"},"source":["# Task 3: Helper notebook for loading the data and saving the predictions"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"odAqj0ZIQwOS","executionInfo":{"status":"ok","timestamp":1671535242056,"user_tz":-60,"elapsed":22266,"user":{"displayName":"Davide","userId":"07926258312875750976"}},"outputId":"705a4b2b-cd3b-4862-8a4b-ca8a3f2891fd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["folder = \"drive/MyDrive/AML_Pr3/\""],"metadata":{"id":"VulBLZ0XQyzW","executionInfo":{"status":"ok","timestamp":1671535242057,"user_tz":-60,"elapsed":4,"user":{"displayName":"Davide","userId":"07926258312875750976"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Tt3ox2GiQqj6","executionInfo":{"status":"ok","timestamp":1671535249024,"user_tz":-60,"elapsed":729,"user":{"displayName":"Davide","userId":"07926258312875750976"}}},"outputs":[],"source":["import pickle\n","import gzip\n","import numpy as np\n","import os"]},{"cell_type":"markdown","metadata":{"id":"221Z8AjFQqj9"},"source":["### Helper functions"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"bZUhUM_DQqj9","executionInfo":{"status":"ok","timestamp":1671535249348,"user_tz":-60,"elapsed":12,"user":{"displayName":"Davide","userId":"07926258312875750976"}}},"outputs":[],"source":["def load_zipped_pickle(filename):\n","    with gzip.open(filename, 'rb') as f:\n","        loaded_object = pickle.load(f)\n","        return loaded_object"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"-94-a7UyQqj-","executionInfo":{"status":"ok","timestamp":1671535249349,"user_tz":-60,"elapsed":11,"user":{"displayName":"Davide","userId":"07926258312875750976"}}},"outputs":[],"source":["def save_zipped_pickle(obj, filename):\n","    with gzip.open(filename, 'wb') as f:\n","        pickle.dump(obj, f, 2)"]},{"cell_type":"markdown","metadata":{"id":"mYJ8xIf0Qqj-"},"source":["### Load data, make predictions and save prediction in correct format"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ANcgrT6zQqj_","executionInfo":{"status":"ok","timestamp":1671535277774,"user_tz":-60,"elapsed":28434,"user":{"displayName":"Davide","userId":"07926258312875750976"}}},"outputs":[],"source":["# load data\n","train_data = load_zipped_pickle(folder + \"train.pkl\")\n","test_data = load_zipped_pickle(folder + \"test.pkl\")\n","samples = load_zipped_pickle(folder + \"sample.pkl\")"]},{"cell_type":"code","source":["for t in train_data:\n","  print(t.keys())\n","  print(t['video'])\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EXZH6qIQTr3o","executionInfo":{"status":"ok","timestamp":1671536180789,"user_tz":-60,"elapsed":316,"user":{"displayName":"Davide","userId":"07926258312875750976"}},"outputId":"e931848f-9d61-4b13-8db5-d4d3232ace40"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['name', 'video', 'box', 'label', 'frames', 'dataset'])\n","[[[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," ...\n","\n"," [[0 0 1 ... 3 0 0]\n","  [0 0 2 ... 0 2 1]\n","  [0 0 1 ... 0 0 1]\n","  ...\n","  [0 0 1 ... 1 2 0]\n","  [1 0 0 ... 1 2 0]\n","  [1 0 0 ... 2 2 0]]\n","\n"," [[0 0 0 ... 3 0 0]\n","  [1 0 0 ... 0 3 2]\n","  [0 0 0 ... 2 1 0]\n","  ...\n","  [1 0 1 ... 0 1 0]\n","  [0 2 0 ... 0 0 0]\n","  [0 1 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 3 2 0]\n","  [3 2 0 ... 2 3 0]\n","  ...\n","  [0 0 1 ... 4 1 1]\n","  [0 7 0 ... 1 1 1]\n","  [0 3 0 ... 0 0 1]]]\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Yb2GAMAnQqj_","executionInfo":{"status":"ok","timestamp":1671535280963,"user_tz":-60,"elapsed":3197,"user":{"displayName":"Davide","userId":"07926258312875750976"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Define the generator and discriminator networks\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n","        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n","        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n","        self.conv5 = nn.Conv2d(512, 1, kernel_size=1, stride=1, padding=0)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv2(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv3(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv4(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv5(x)\n","        x = nn.functional.sigmoid(x)\n","        return x\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.conv1 = nn.Conv2d(2, 64, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n","        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n","        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n","        self.conv5 = nn.Conv2d(512, 1, kernel_size=1, stride=1, padding=0)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv2(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv3(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv4(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv5(x)\n","        x = nn.functional.sigmoid(x)\n","        return x"]},{"cell_type":"code","source":["def wasserstein_loss(y_true, y_pred):\n"," return mean(y_true) * mean(y_pred)\n","#from torch.nn.functional import wasserstein_distance\n","from torch.nn import SoftMarginLoss, SmoothL1Loss"],"metadata":{"id":"AVSA0ZulRUT7","executionInfo":{"status":"ok","timestamp":1671537497741,"user_tz":-60,"elapsed":295,"user":{"displayName":"Davide","userId":"07926258312875750976"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"Mx8nuAywQqkA","executionInfo":{"status":"error","timestamp":1671537500858,"user_tz":-60,"elapsed":336,"user":{"displayName":"Davide","userId":"07926258312875750976"}},"outputId":"fbbe75a5-6d20-4154-fc06-4c8292e8d8f4"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-e560e81ebd02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Create a \"fake\" segmentation map using the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mfake_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Concatenate the real and fake images and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-ff631be397a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (unsigned char) and bias type (float) should be the same"]}],"source":["# Set up the model, loss function, and optimizers\n","generator = Generator()\n","discriminator = Discriminator()\n","bce_loss = nn.BCELoss()\n","wasserstein_loss = SoftMarginLoss() #wasserstein_loss\n","\n","d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","num_epochs = 10\n","batch_size = 1000\n","# Train the model\n","for epoch in range(num_epochs):\n","    for t in train_data:\n","        images = torch.tensor(t['video'])\n","        labels = torch.tensor(t['label'])\n","        # Resize images and labels to match the input size of the generator\n","        img_size = t['video'].shape\n","        images = images.resize_(batch_size, 3, img_size[0], img_size[1])\n","        labels = labels.resize_(batch_size, 1, img_size[0], img_size[1])\n","\n","        # Create a \"fake\" segmentation map using the generator\n","        fake_labels = generator(images)\n","\n","        # Concatenate the real and fake images and labels\n","        real_fake_images = torch.cat((images, fake_labels), 1)\n","        real_fake_labels = torch.cat((labels, labels), 1)\n","\n","        # Train the discriminator\n","        d_optimizer.zero_grad()\n","        d_output = discriminator(real_fake_images, real_fake_labels)\n","        d_real_loss = wasserstein_loss(d_output[:, :1], torch.ones(batch_size, 1, img_size, img_size))\n","        d_fake_loss = wasserstein_loss(d_output[:, 1:], torch.zeros(batch_size, 1, img_size, img_size))\n","        d_loss = d_real_loss + d_fake_loss\n","        d_loss.backward()\n","        d_optimizer.step()\n","\n","        # Train the generator\n","        g_optimizer.zero_grad()\n","        g_output = discriminator(real_fake_images, real_fake_labels)\n","        g_loss = wasserstein_loss(g_output[:, 1:], torch.ones(batch_size, 1, img_size, img_size))\n","        g_loss.backward()\n","        g_optimizer.step()"]},{"cell_type":"code","source":["#### GANs\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Define the generator and discriminator networks\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n","        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n","        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n","        self.conv5 = nn.Conv2d(512, 1, kernel_size=1, stride=1, padding=0)\n","\n","    def forward(self, x):\n","        print(x)\n","        print(type(x))\n","        x = self.conv1(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv2(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv3(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv4(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv5(x)\n","        x = nn.functional.sigmoid(x)\n","        return x\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.conv1 = nn.Conv2d(2, 64, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n","        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n","        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n","        self.conv5 = nn.Conv2d(512, 1, kernel_size=1, stride=1, padding=0)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv2(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv3(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv4(x)\n","        x = nn.functional.relu(x)\n","        x = self.conv5(x)\n","        x = nn.functional.sigmoid(x)\n","        return x\n","\n","# Set up the model, loss function, and optimizers\n","generator = Generator()\n","discriminator = Discriminator()\n","bce_loss = nn.BCELoss()\n","d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n","g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n","\n","# Train the model\n","for epoch in range(num_epochs):\n","    for t in train_data:\n","        images = torch.tensor(t['video'])\n","        labels = torch.tensor(t['label'])\n","        \n","        # Resize images and labels to match the input size of the generator\n","        images = images.resize_(batch_size, 3, img_size[0], img_size[1])\n","        labels = labels.resize_(batch_size, 1, img_size[0], img_size[1])\n","\n","        # Create a \"fake\" segmentation map using the generator\n","        fake_labels = generator(images)\n","\n","        # Concatenate the real and fake images and labels\n","        real_fake_images = torch.cat((images, fake_labels), 1)\n","        real_fake_labels = torch.cat((labels, labels), 1)\n","\n","        # Train the discriminator\n","        d_optimizer.zero_grad()\n","        d_output = discriminator(real_fake_images, real_fake_labels)\n","        d_real_loss = bce_loss(d_output[:, :1], torch.ones(batch_size, 1, img_size, img_size))\n","        d_fake_loss = bce_loss(d_output[:, 1:], torch.zeros(batch_size, 1, img_size, img_size))\n","        d_loss = d_real_loss + d_fake_loss\n","        d_loss.backward()\n","        d_optimizer.step()\n","\n","        # Train the generator\n","        g_optimizer.zero_grad()\n","        g_output = discriminator(real_fake_images, real_fake_labels)\n","        g_loss = bce_loss(g_output[:, 1:], torch.ones(batch_size, 1, img_size, img_size))\n","        g_loss.backward()\n","        g_optimizer.step()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hOy0m4Wuapzc","executionInfo":{"status":"error","timestamp":1671537985468,"user_tz":-60,"elapsed":312,"user":{"displayName":"Davide","userId":"07926258312875750976"}},"outputId":"02288b36-c33a-48e3-aaca-cee4725335f5"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n","\n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n","\n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 1, 1, 1],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]]],\n","\n","\n","        [[[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n","\n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n","\n","         [[0, 0, 0,  ..., 1, 1, 1],\n","          [1, 1, 1,  ..., 1, 1, 1],\n","          [1, 1, 1,  ..., 1, 1, 1],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]]],\n","\n","\n","        [[[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n","\n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 1, 1, 1],\n","          [1, 1, 1,  ..., 1, 1, 1]],\n","\n","         [[1, 1, 1,  ..., 1, 1, 1],\n","          [1, 1, 1,  ..., 1, 1, 1],\n","          [1, 1, 1,  ..., 1, 1, 1],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n","\n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n","\n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]]],\n","\n","\n","        [[[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n","\n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n","\n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]]],\n","\n","\n","        [[[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n","\n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n","\n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]]]], dtype=torch.uint8)\n","<class 'torch.Tensor'>\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-5ec3f0fddef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Create a \"fake\" segmentation map using the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mfake_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Concatenate the real and fake images and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-48-5ec3f0fddef1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (unsigned char) and bias type (float) should be the same"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9SKwFcYSQqkB","executionInfo":{"status":"aborted","timestamp":1671535281549,"user_tz":-60,"elapsed":13,"user":{"displayName":"Davide","userId":"07926258312875750976"}}},"outputs":[],"source":["# make prediction for test\n","predictions = []\n","for d in test_data:\n","    prediction = np.array(np.zeros_like(d['video']), dtype=np.bool)\n","    height = prediction.shape[0]\n","    width = prediction.shape[1]\n","    prediction[int(height/2)-50:int(height/2+50), int(width/2)-50:int(width/2+50)] = True\n","    \n","    # DATA Strucure\n","    predictions.append({\n","        'name': d['name'],\n","        'prediction': prediction\n","        }\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ojGlkeZwQqkC","executionInfo":{"status":"aborted","timestamp":1671535281550,"user_tz":-60,"elapsed":12,"user":{"displayName":"Davide","userId":"07926258312875750976"}}},"outputs":[],"source":["# save in correct format\n","save_zipped_pickle(predictions, 'my_predictions.pkl')"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"b629c3126b5df0b3c19ac5f524890cb3a3a2e86c1a2f2c4b1c29287aa73e65d0"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}